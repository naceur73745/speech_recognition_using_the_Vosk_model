# -*- coding: utf-8 -*-
"""Real-time speech recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/151X7cO2p_Ur9ErN0K5m1Nvh6OY3Nbcz8
"""

import ipywidgets as widgets
from IPython.display import display
from queue import Queue
from threading import Thread


messages = Queue()
recordings = Queue()

#craete the recored button and stop button 

button_for_recording = widgets.Button(
    description='record',
    disabled=False,
    button_style='success',
    tooltip='Record',
    icon='microphone'
)

button_to_stop = widgets.Button(
    description='stop',
    disabled=False,
    button_style='warning',
    tooltip='Stop',
    icon='stop'
)
#create the widget  

output = widgets.Output()
#start recordding 

def start_recording(data):
    messages.put(True)
    
    with output:
        display("Starting...")
        record = Thread(target=record_microphone)
        record.start()
        transcribe = Thread(target=speech_recognition, args=(output,))
        transcribe.start()

def stop_recording(data):
    with output:
        messages.get()
        display("Stopped.")
    
record_button.on_click(start_recording)
stop_button.on_click(stop_recording)

display(record_button, stop_button, output)


#we defined the button 's  now let start  defining the  functions 
#get  all the devices on my coimputer  
# Install pyaudio from http://people.csail.mit.edu/hubert/pyaudio/
# Find audio device index using thiscode

import pyaudio
p = pyaudio.PyAudio()
for i in range(p.get_device_count()):
    print(p.get_device_info_by_index(i))

p.terminate()

#index  of  my microphone  is 0 
#define fnction  for recording  the voice 
CHANNELS = 1
FRAME_RATE = 16000
RECORD_SECONDS = 20
AUDIO_FORMAT = pyaudio.paInt16
SAMPLE_SIZE = 2

def record_microphone(chunk=1024):
    p = pyaudio.PyAudio()

    stream = p.open(format=AUDIO_FORMAT,
                    channels=CHANNELS,
                    rate=FRAME_RATE,
                    input=True,
                    input_device_index=2,
                    frames_per_buffer=chunk)

    frames = []

    while not messages.empty():
        data = stream.read(chunk)
        frames.append(data)
        if len(frames) >= (FRAME_RATE * RECORD_SECONDS) / chunk:
            recordings.put(frames.copy())
            frames = []

    stream.stop_stream()
    #  stream 
    stream.close()
    p.terminate()
    
#define dfunction also for stopping the voice

#speech recogniton using the api  
import subprocess
import json
from vosk import Model, KaldiRecognizer
import time
#we can use other model fi we want  tov 
model = Model(model_name="vosk-model-small-en-us-0.15")

rec = KaldiRecognizer(model, FRAME_RATE)
rec.SetWords(True)
    
def speech_recognition(output):
    
    while not messages.empty():
        frames = recordings.get()
        
        rec.AcceptWaveform(b''.join(frames))
        result = rec.Result()
        text = json.loads(result)["text"]
        
        cased = subprocess.check_output('python recasepunc/recasepunc.py predict recasepunc/checkpoint', shell=True, text=True, input=text)
        output.append_stdout(cased)
        time.sleep(1)